########################################################################################################
# THIS PROGRAM AGGREGATES DATA OVER MONITORING WINDOW
# THE DATA IS THEN USED TO FIT AND APPLY PD MODELS
# 
# File Version: 1.1
# Last Modified: 2014-MAY-28
########################################################################################################

rm(list=ls())
wrkDir <- Sys.getenv("R_TMP")
setwd(wrkDir)

library(reshape)

#####################################
# Input Data - HM_DM_WRK_AREA Views
#
# 1. V_W_PD_IN_CLINICAL_STUDY
# 2. V_W_PD_IN_CLINICAL_STUDY_SITE
# 3. V_W_PD_IN_SITE_VISIT
# 4. V_W_PD_IN_SUBJECT
# 5. V_W_PD_IN_PROTOCOL_DEVIATION 
#
#######################################

source("/app/r/engine/SiteHealthLogger.R")
source("/app/r/engine/RODBCDataFetch.R")

logInfo("Reading in PD Data from the Data Mart WRK Area Views...")
	
# Read in data from the WRK Area Views
V_W_PD_IN_CLINICAL_STUDY <- getPDStudyData()
V_W_PD_IN_CLINICAL_STUDY_SITE <- getPDSiteData()
V_W_PD_IN_SUBJECT <- getPDSubjectData()
V_W_PD_IN_PROTOCOL_DEVIATION <- getPDData()
V_W_PD_IN_SITE_VISIT <- getPDSiteVisits()
	
logInfo("Done reading in PD Data from the DM...")
	
# Classify Date fields in the site data

V_W_PD_IN_CLINICAL_STUDY_SITE$SITE_FSFV_DATE <- as.Date(V_W_PD_IN_CLINICAL_STUDY_SITE$SITE_FSFV_DATE)
V_W_PD_IN_CLINICAL_STUDY_SITE$SITE_FSFV_DATE_DERIVED <- as.Date(V_W_PD_IN_CLINICAL_STUDY_SITE$SITE_FSFV_DATE_DERIVED)
V_W_PD_IN_CLINICAL_STUDY_SITE$SITE_LSLV_DATE <- as.Date(V_W_PD_IN_CLINICAL_STUDY_SITE$SITE_LSLV_DATE)
V_W_PD_IN_CLINICAL_STUDY_SITE$SITE_LSLV_DATE_DERIVED <- as.Date(V_W_PD_IN_CLINICAL_STUDY_SITE$SITE_LSLV_DATE_DERIVED)
V_W_PD_IN_CLINICAL_STUDY_SITE$LAST_MVR_DATE <- as.Date(V_W_PD_IN_CLINICAL_STUDY_SITE$LAST_MVR_DATE)

	##############################################################################
	# Subset master study algorithm data to those studies that are usable 
	# Section not needed for running of PD algorithm

	#pd_modeling <- V_W_PD_IN_CLINICAL_STUDY[V_W_PD_IN_CLINICAL_STUDY$YN_PD_EXCLUDED %in% c("N"),] 
	#pd_modeling_studies <- pd_modeling$HM_STUDY_ID

	#length(pd_modeling_studies) # 818 studies 
	##############################################################################
	
	# Subset sites to those that met site inclusion criteria met (# of subjects, etc)
	# and have had a monitoring visit within the past 5 years
	# and have had a monitoring visit since FSFV

	studyCt <- nrow(V_W_PD_IN_CLINICAL_STUDY)   #786 studies 
	studySiteCt <- nrow(V_W_PD_IN_CLINICAL_STUDY_SITE) #20,716 sites...
	
	logInfo("Initial study counts available for use -> YN_EXCLUDED=N and YN_PD_EXCLUDED=N:", studyCt)
	logInfo("Initial site counts available for use -> YN_EXCLUDED=N and YN_PD_EXCLUDED=N:", studySiteCt)
		
	site_use <<- V_W_PD_IN_CLINICAL_STUDY_SITE[which(V_W_PD_IN_CLINICAL_STUDY_SITE$YN_PD_EXCLUDED=="N" & 
						V_W_PD_IN_CLINICAL_STUDY_SITE$LAST_MVR_DATE>(Sys.Date() - 365.25*5) & 
						(V_W_PD_IN_CLINICAL_STUDY_SITE$LAST_MVR_DATE >  V_W_PD_IN_CLINICAL_STUDY_SITE$SITE_FSFV_DATE_DERIVED)),] # Using SITE_FSFV_DATE_DERIVED produced in data mart
	site_useCt <- nrow(site_use) #11,625 sites used 
	logInfo("Site counts after sub-setting: LAST_MVR_DATE > SITE_FSFV_DATE_DERIVED && LAST_MVR_DATE in the last 5yrs:", site_useCt)
	
	######################################################################
	# Subset PD data to studies/sites that are in scope 
	######################################################################
	
		# Classify PD date field
		V_W_PD_IN_PROTOCOL_DEVIATION$DATE_DEVIATION_NOTED <- as.Date(V_W_PD_IN_PROTOCOL_DEVIATION$DATE_DEVIATION_NOTED)
		
		pd <- V_W_PD_IN_PROTOCOL_DEVIATION[which(V_W_PD_IN_PROTOCOL_DEVIATION$HM_SITE_ID %in%c(site_use$HM_SITE_ID)) ,]
		pdCt <- nrow(pd) # 241,340 
		logInfo("Initial PDs available for use:", pdCt)
		
		pd_use <<- pd[order(pd$HM_SITE_ID,pd$DATE_DEVIATION_NOTED),]

	##############################################################################
	# ADJUSTMENTS TO SUBJECT DATA (section added for implementation)
      ##############################################################################
	
	# Classify Dates fields in subject data
	V_W_PD_IN_SUBJECT$SUBJ_COMPLETED_STUDY_DT <- as.Date(V_W_PD_IN_SUBJECT$SUBJ_COMPLETED_STUDY_DT)
	V_W_PD_IN_SUBJECT$SUBJ_DISCONTINUED_DT <- as.Date(V_W_PD_IN_SUBJECT$SUBJ_DISCONTINUED_DT)
	V_W_PD_IN_SUBJECT$SUBJ_ENROLLED_STUDY_DT <- as.Date(V_W_PD_IN_SUBJECT$SUBJ_ENROLLED_STUDY_DT)
	V_W_PD_IN_SUBJECT$SUBJ_ENROLLED_STUDY_DT_DERIVED <- as.Date(V_W_PD_IN_SUBJECT$SUBJ_ENROLLED_STUDY_DT_DERIVED)
	V_W_PD_IN_SUBJECT$SUBJ_STATUS <- as.character(V_W_PD_IN_SUBJECT$SUBJ_STATUS)

	# 1) Remove:
    	#   	a) screen fails
	#	b) those without enrollment dates
	#	c) those without HM study id matches

	subjCt <- nrow(V_W_PD_IN_SUBJECT) #254,478
    	logInfo("Initial Subject counts for use", subjCt)

	subject_mashup2 <- V_W_PD_IN_SUBJECT[which( 
				#!is.na(V_W_PD_IN_SUBJECT$SUBJ_ENROLLED_STUDY_DT) &    ### ACTION: SUBJ_ENROLLED_STUDY_DT_DERIVED <- why is this not being used? 
				!is.na(V_W_PD_IN_SUBJECT$SUBJ_ENROLLED_STUDY_DT_DERIVED) & 
				!is.na(V_W_PD_IN_SUBJECT$SUBJ_STATUS) & 
				!(V_W_PD_IN_SUBJECT$SUBJ_STATUS=="SCREEN FAIL") & 
				!is.na(V_W_PD_IN_SUBJECT$HM_SITE_ID)),]

	subject_mashup2_ct <- nrow(subject_mashup2) #186,659
	logInfo("Subject data count after sub-setting: are not SCREEN FAIL, have a SUBJ_ENROLLED_STUDY_DT and SUBJ_ENROLLED_STUDY_DT:", subject_mashup2_ct)
	
	# Merge Site data onto subject mashup
	subject_mashup3 <- merge(subject_mashup2,V_W_PD_IN_CLINICAL_STUDY_SITE[,c("HM_SITE_ID","SITE_STATUS","SITE_LSLV_DATE_DERIVED")],by="HM_SITE_ID",all.x=T)
	
	# 2) Remove old/completed studies with all subject status "stuck" in SCREENED 
	 temp=table(subject_mashup3$HM_STUDY_ID,subject_mashup3$SUBJ_STATUS)
	 all.screened.id=as.numeric(row.names(temp[which(apply(temp,1,sum,na.rm=T)==temp[,5]),]))
	 subject_mashup3=subject_mashup3[!(subject_mashup3$HM_STUDY_ID%in%all.screened.id),]

	logInfo("The following HM_STUDY_IDs have all their subjects in Screened Status and were removed", all.screened.id)

	# 3) Create a modeling end date variable (used later in various aggregators - models)
	#    If subject has completion date, use the completion date
	#        else if subject has discontinuation date, use the discontinuation date
	#            else if site is closed/terminated, use the LSLV date for the site (regardless of subject status... note: implication screen fails
	#                                     not included (since removed) but does include all other statuses including SCREENED, ENROLLED/RANDOMIZED, etc.)
	# 	NA value for this variables implies the subject is either on active treatment or in follow-up 
	
	subject_mashup3$MODELING_END_DT <- subject_mashup3$SUBJ_COMPLETED_STUDY_DT
	subject_mashup3$MODELING_END_DT <- ifelse(is.na(subject_mashup3$MODELING_END_DT), subject_mashup3$SUBJ_DISCONTINUED_DT,subject_mashup3$MODELING_END_DT)
	subject_mashup3$MODELING_END_DT <- ifelse(is.na(subject_mashup3$MODELING_END_DT) & subject_mashup3$SITE_STATUS%in%c("COMPLETED","TERMINATED"), subject_mashup3$SITE_LSLV_DATE_DERIVED,subject_mashup3$MODELING_END_DT)
	subject_mashup3$MODELING_END_DT <- as.Date(subject_mashup3$MODELING_END_DT,origin="1970-01-01")

	# 4) Subject Status (NOT CURRENTLY RUN)
	#    For purposes of comparing subject counts to control totals, keep Screened in separate category (for some studies, unusually high proportions
	#        of subjects remain in the "SCREENED" status).  Imputing the same end data for all of them is likely not appropriate.
	#    For purposes of modeling, in completed/terminated sites, change subject status to complete
	#	note: already excluded sites with all screened patients 

		# Might not be necessary to include
		#sum(subject_mashup3$SITE_STATUS%in%c("Completed","Terminated") & !subject_mashup3$MERGE_SUBJECT_STATUS%in%c("COMPLETED","DISCONTINUED"), na.rm=T) #25,796; a large number of subjects have not been "close out"
		#subject_mashup3$EXCLU_SUBSET_SUBJECT_STATUS <- ifelse(subject_mashup3$SITE_STATUS%in%c("Completed","Terminated"),"COMPLETED",subject_mashup3$MERGE_SUBJECT_STATUS)

		# Create a modeling subject status: COMPLETED and TERMINATED = 'Completed'

		table(subject_mashup3$MODELING_SUBJECT_STATUS)
		subject_mashup3$MODELING_SUBJECT_STATUS <- ifelse(subject_mashup3$SITE_STATUS%in%c("COMPLETED","TERMINATED"),"Completed",subject_mashup3$SUBJ_STATUS)
		subject <- subject_mashup3

		# Subset subject data to sites meeting algorithm criteria
		subject_use <<- subject[which(subject$HM_SITE_ID %in%c(site_use$HM_SITE_ID)) ,]
		
		subject_use_ct <- nrow(subject_use) #129,049
		logInfo("[FINAL] Subject counts that will be used in the PD analysis:", subject_use_ct)
		
	##############################################################################
	# Subset site visit (MVR) data to studies/sites that are in scope 
      # TO DO: Check to see if there are NULL VISIT_REPORT_TYPE values
	##############################################################################
	
	visit_mv <- V_W_PD_IN_SITE_VISIT[which(is.na(V_W_PD_IN_SITE_VISIT$VISIT_REPORT_TYPE) | V_W_PD_IN_SITE_VISIT$VISIT_REPORT_TYPE%in%c("MONITORING VISIT REPORT","")),]
		
	siteVisitCt <- nrow(V_W_PD_IN_SITE_VISIT) #135,109
	logInfo("Original Site Visit data count:", siteVisitCt)
		
	visit_mv_ct <- nrow(visit_mv) # 115,601
	logInfo("Site Visit data count after data sub-setting to Monitoring Visit Report:", visit_mv_ct)
		
	# Classify start date field in visit data
	visit_mv$VISIT_START_DATE <- as.Date(visit_mv$VISIT_START_DATE)

######################################################################################################
# ADDITION: TEST TO SEE THAT LAST MVR DATE IS CORRECT
# mvi_last <- aggregate(visit_mv$VISIT_START_DATE,list(HM_SITE_ID=visit_mv$HM_SITE_ID),max,na.rm=T)
# names(mvi_last)[2] <- "MVI_DATE_LAST"	

# Merge MV last date onto site data
# MV_Date_Test <- merge(V_W_PD_IN_CLINICAL_STUDY_SITE, mvi_last, by="HM_SITE_ID", all.x=T)
# MV_Date_Test$date_difference <- MV_Date_Test$MVI_DATE_LAST - MV_Date_Test$LAST_MVR_DATE
# table(MV_Date_Test$date_difference)# Only value should be 0, if not then there are differences there may be issues with the LAST_MVR_DATE
#####################################################################################################

	# This start date restriction will/should be lifted on go-live data
	#visit_use <- visit_mv[which(visit_mv$HM_SITE_ID%in%site_use$HM_SITE_ID & visit_mv$VISIT_START_DATE<"2013-09-01"),]# not needed in implementation
	visit_use <- visit_mv[which(visit_mv$HM_SITE_ID%in%site_use$HM_SITE_ID),]	

	# Update site_use table to only include sites that have at least one monitoring visit listed in the visit data
	site_use <<- site_use[which(site_use$HM_SITE_ID%in%visit_use$HM_SITE_ID),]
	
	site_use_CtFinal <- nrow(site_use) #11,625

	logInfo("[FINAL] Site counts that will be used in the PD analysis:", site_use_CtFinal)

	####################################
	###    CUSTOM COUNT FUNCTIONS    ###
	####################################

	# Functions to get counts between 2 dates under different scenarios (event has single date, "event" spans a start and end time)

	# Function to get counts when given a single event date. Needs 2 column matrix of start and end dates for a period.
	countsinperiod <- function(period,datevariable){
		apply(period,1,function(f){sum((f[1] <= datevariable) & (datevariable <= f[2]),na.rm=T) })
	}

	# Function to get counts of participants (e.g. staff or patients) when given start and end dates, counted as 1
	# if any participation in the period. Inputs: 2 column matrix of start and end dates for a period
	# and start and end dates for the participants.
	countsinperiod2dates <- function(period,datevariables){
		apply(period,1,function(f){sum(
			((f[1] <= datevariables[,1]) & (datevariables[,1] <=f[2])) |
			((f[1] <= datevariables[,2]) & (datevariables[,2]<=f[2])) |
			((datevariables[,1]< f[1]) & (f[2] < datevariables[,2])),na.rm=T)})
		}

	# Function to get counts of participants (e.g. staff or patients) when given start and end dates, scaled
	# by how much of the period they participated in.  Inputs: 2 column matrix of start and end dates for a period
	# and start and end dates for the participants.
	countsinperiod2dates_scale <- function(period,datevariables){
		apply(period,1,function(f){
			periodlength <- as.numeric(f[2] - f[1])
			temp=rep(NA,dim(datevariables)[1])

			use.datevariables=datevariables
			use.datevariables[,1]=ifelse(use.datevariables[,1]<f[1],f[1],use.datevariables[,1])
			use.datevariables[,2]=ifelse(use.datevariables[,2]>f[2],f[2],use.datevariables[,2])

			replace.these=which(!((f[2] < datevariables[,1]) | (datevariables[,2] < f[1])))
			temp[replace.these]=as.numeric(use.datevariables[replace.these,2] - use.datevariables[replace.these,1])/periodlength

			sum(temp,na.rm=T)})
		}

	# Function to aggregate counts and other events within monitoring windows
	acrosstime2 <- function(i){

	site_ <- site_use[which(site_use$HM_SITE_ID==i),]

		# Subsetting subject data for subjects associated with the site 
		subject_ <- subject_use[which(subject_use$HM_SITE_ID==i),]

	
	# For end date, use today's date if others are not given.  

	pd_ <- pd_use[which(pd_use$HM_SITE_ID==i & pd_use$DATE_DEVIATION_NOTED<=Sys.Date()),] 
	pd_comp= pd_ <- pd_use[which(pd_use$HM_SITE_ID==i),] 

	visit_ <- visit_use[which(visit_use$HM_SITE_ID==i),]
	visit_ <- visit_[order(visit_$VISIT_START_DATE),]

	visit_dates <- unique(visit_$VISIT_START_DATE)
	
	# remove the later of two dates that are only a day apart
	if(length(visit_dates)>1){
		visit_dates <- visit_dates[c(1,which(visit_dates[2:length(visit_dates)] - visit_dates[1:(length(visit_dates)-1)] > 1)+1)]
	}	

	# define maximum MV date and minimum subject enrollment date 
	maxvisitdate <- max(visit_dates, na.rm=T)
	minsubdate <- as.Date(min(subject_$SUBJ_ENROLLED_STUDY_DT_DERIVED, na.rm=T))

	# ID PDs that are outside acceptable timeframe (30 days past the the most recent maximum monitoring visit date)
	# NOTE: marking of inconsistent PDs is performed outside of R. This count is maintained as a test of the performance of this task
	inconsistent.pds=ifelse(is.na(maxvisitdate ), 0, sum(pd_comp$DATE_DEVIATION_NOTED>as.Date(maxvisitdate +30))) 	

	if (length(which(visit_dates>Sys.Date()))>0){
	visit_dates=visit_dates[-which(visit_dates>Sys.Date())]} #Check for unreasonable MV dates

	# Remove monitoring visits that happen before first patient is enrolled
	# The model should only be used when at least one patient is enrolled 

	if (length(which(visit_dates<minsubdate))>0){
	visit_dates=visit_dates[-which(visit_dates<minsubdate)]}  #Last Period is a catch-all and should not be visualized or used in analyses

	PERIOD_START <- c(as.Date("2001-01-01"),minsubdate,visit_dates) 
	PERIOD_END <- c(minsubdate-1,visit_dates-1,as.Date(maxvisitdate +30))

	dat <- data.frame(HM_SITE_ID=i,PERIOD_START,PERIOD_END, inconsistent.pds)

	###########################################################################
	# PATIENT ENROLLMENT: Count the number of patients on active treatment
      # or follow-up at any point during the period
	###########################################################################
	if (sum(is.na(subject_$MODELING_END_DT))>0) {subject_$MODELING_END_DT[is.na(subject_$MODELING_END_DT)]=Sys.Date()}
	dat$PAT_COUNT <- countsinperiod2dates(cbind(PERIOD_START,PERIOD_END),cbind(subject_$SUBJ_ENROLLED_STUDY_DT_DERIVED,subject_$MODELING_END_DT))

	# Count number of patients on active treatment or follow-up in the period scaled by how much of the period they were enrolled for
	dat$PAT_COUNT_SCALE <- 	countsinperiod2dates_scale(cbind(PERIOD_START,PERIOD_END),cbind(subject_$SUBJ_ENROLLED_STUDY_DT_DERIVED,subject_$MODELING_END_DT))

	# Count the number of patients enrolled during the period
	# TO DO: May not be used - potentially remove - may be used in future
	dat$PAT_ENRL_COUNT <- countsinperiod(cbind(PERIOD_START,PERIOD_END),subject_$SUBJ_ENROLLED_STUDY_DT_DERIVED)

	# Count the number of discontinued/completed patients within the Monitoring Window
	# TO DO: May not be used - potentially remove or leave if it may be used in future
	dat$PAT_TERM_COUNT <- countsinperiod(cbind(PERIOD_START,PERIOD_END),subject_$MODELING_END_DT)

	dat$PERIOD_SINCE_FSFV=0:(nrow(dat)-1)

	# PROTOCOL DEVIATION COUNTS
	# Count of number of pds in the period - REMEMBER TO MOVE TO PREVIOUS PERIOD
	dat$PD_COUNT <- countsinperiod(cbind(PERIOD_START,PERIOD_END),as.Date(pd_$DATE_DEVIATION_NOTED))
		
	dat$PD_COUNT_IN_PERIODS=sum(dat$PD_COUNT, na.rm=T)
	dat$PD_COUNT_TOTAL=nrow(pd_)

	dat[,-which(names(dat)%in%c("PERIOD_SINCE_FSFV"))][is.na(dat[,-which(names(dat)%in%c("PERIOD_SINCE_FSFV"))])] <- 0
	rm(pd_,subject_,visit_,site_)
	return(dat)	
	}

	# Function to apply data aggregator function to all study IDs simultaneously
	studyaggs <- function(j){
		siteevals <- site_use[site_use$HM_STUDY_ID==j,"HM_SITE_ID"]
		data.frame(HM_STUDY_ID=j,do.call(rbind,lapply(siteevals,FUN=acrosstime2)))
	}
	
	studyevals <- unique(site_use$HM_STUDY_ID)
	N_study <- length(studyevals)

	# Perform the monitoring window identification and various counting operations
	all <- do.call(rbind,lapply(studyevals,FUN=studyaggs)) # Warnings produced here are acceptable.  Errors are not.

	#dim(all) # 114,835 ####  135,786 records (166,059)

		### all$PD_COUNT_IN_PERIODS & all$PD_COUNT_TOTAL can be used to assess which PDs get left out and why 

		temp.all=unique(all[,c("HM_STUDY_ID","HM_SITE_ID", "PD_COUNT_IN_PERIODS","PD_COUNT_TOTAL","inconsistent.pds")])
		#dim(temp.all) # 11,625

#########################################################################################################################################################
# Output of sites with inconsistent PD about 10% of total PDs (produced as check of implementation, remove after issue is corrected)
#inconsitent_PD_Site <-temp.all[temp.all$inconsistent.pds >0,]
#inconsitent_PD_Site$Percentage_Inconsistent <- inconsitent_PD_Site$inconsistent.pds/inconsitent_PD_Site$PD_COUNT_TOTAL
#inconsitent_PD_Site <- inconsitent_PD_Site[inconsitent_PD_Site$Percentage_Inconsistent >=.1,]
#dim(inconsitent_PD_Site)
#write.csv(inconsitent_PD_Site, file=paste(lib.outmodel,"Sites with inconsistent PDs 04-04-12.csv",sep=""))
#########################################################################################################################################################

	# Consider sites with 10% or more of PDs post modeling end date as not usable

	keep.ids=temp.all$HM_SITE_ID[which((temp.all$inconsistent.pds/temp.all$PD_COUNT_TOTAL)<.1 | temp.all$PD_COUNT_TOTAL==0)]
		
	length(keep.ids)
 	sites_inconsistent_pds=nrow(temp.all)-length(keep.ids) # Results should be 0 in Implementation. 1,065 sites have issues potentially with PD dates outside acceptable range (1,090)
	
	logInfo("The following number of sites were removed due to inconsistent PDs exceeding the 10 percent threshold", sites_inconsistent_pds)

	# Include only those sites in analyses that have fewer than 10% of PDs recorded past Max Visit Date + 30 
	#temp.all$HM_SITE_ID[which((temp.all$inconsistent.pds/temp.all$PD_COUNT_TOTAL)>=.1)]

	all$PERIOD_LENGTH <- as.numeric(all$PERIOD_END - all$PERIOD_START)
     	#17-JUN-2014: Commented out due to dimension error
	#all <- all[all$PERIOD_LENGTH >= 0 & all$HM_SITE_ID%in%keep.ids,] # This should not be needed in the live environment, when everything run through "Today"
	#dim(all) # 87,939   
	
	# LAG THE PD COUNTS INTO THE PREVIOUS PERIOD; SHOULD THE "EMPTY" PERIOD BE RETAINED
	all$PD_COUNT_NEXT <- c(all$PD_COUNT[2:(dim(all)[1])],0)
	all$PD_COUNT_NEXT[c(all$HM_SITE_ID[1:(dim(all)[1]-1)],0) != 
					 c(all$HM_SITE_ID[2:(dim(all)[1])],0)] <- NA 

#################################################################################################
# PD MODEL - THIS PROGRAM 
#
# 1) FITS A REGRESSION MODEL TO PREDICT PD COUNTS AT A SITE 
# 2) APPLIES MODEL COEFFICIENTS TO ONGOING SITES
##################################################################################################

# PREPARE DATA FOR USE IN THE PD REGRESSION MODEL

	# Merge PD data ("all") with site_country information that was created
	all_attrib <- merge(all,V_W_PD_IN_CLINICAL_STUDY_SITE[,c("HM_SITE_ID","COUNTRY_NAME")],by="HM_SITE_ID",all.x=T)
	#sum(all_attrib$COUNTRY_NAME=="UNKNOWN") # sum should be 0

# SUBSET DATA: GET RID OF the DUMMY FIRST AND LAST PERIODS (First Period is between 2001-01-01 and FSFV; and Last period is between Max Visit Date + 30 

# Setting a default date for PERDIOD_START.  This is set in the Aggregator
	alg_pd <- all_attrib[which(!(all_attrib$PERIOD_START == "2001-01-01" | is.na(all_attrib$PD_COUNT_NEXT))),]
	#dim(alg_pd) #72,706 records 
	
	alg_pd <- alg_pd[order(alg_pd$HM_SITE_ID,alg_pd$PERIOD_START),]
	alg_pd$TIME_SINCE_FSFV <-  do.call(c,by(alg_pd$PERIOD_LENGTH*(alg_pd$PERIOD_SINCE_FSFV>=0), alg_pd$HM_SITE_ID, cumsum))

	# If fewer than 10 sites per study, roll them up into FEW OBS
	
	temp=unique(alg_pd[,c("HM_STUDY_ID","HM_SITE_ID")])
	sitesperstudy <- table(temp$HM_STUDY_ID)
	#table(as.numeric(sitesperstudy ))
	good.studies <- names(sitesperstudy[sitesperstudy>=10])
	alg_pd$STUDY <- as.factor(ifelse(alg_pd$HM_STUDY_ID%in%good.studies,as.character(alg_pd$HM_STUDY_ID),"FEW OBS"))
	
	# If fewer than 10 sites per country, then combine them all into "OTHER" category
	temp=unique(alg_pd[,c("HM_STUDY_ID","HM_SITE_ID","COUNTRY_NAME")])
	sitespercountry <- table(temp$COUNTRY_NAME)
	#table(as.numeric(sitespercountry))
	good.countries <- names(sitespercountry[sitespercountry>=10])
	alg_pd$COUNTRY <- as.factor(ifelse(alg_pd$COUNTRY_NAME%in%good.countries,as.character(alg_pd$COUNTRY_NAME),"OTHER"))

	# Cap Patient Counts and PD counts 
	alg_pd$PAT_COUNT.capped <- ifelse(alg_pd$PAT_COUNT<=quantile(alg_pd$PAT_COUNT,.99, na.rm=T),alg_pd$PAT_COUNT,quantile(alg_pd$PAT_COUNT,.99, na.rm=T))
	#max(alg_pd$PAT_COUNT.capped,na.rm=T) # 88; Capped at 71 (64) patients 
	
	alg_pd$PAT_COUNT_SCALE.capped <- ifelse(alg_pd$PAT_COUNT_SCALE<=quantile(alg_pd$PAT_COUNT_SCALE,.99, na.rm=T),alg_pd$PAT_COUNT_SCALE,quantile(alg_pd$PAT_COUNT_SCALE,.99, na.rm=T))
	#max(alg_pd$PAT_COUNT_SCALE.capped,na.rm=T) # 86; Capped at 69 (59.3) patients 
	
	alg_pd$PD_COUNT_NEXT.capped <- ifelse(alg_pd$PD_COUNT_NEXT<=quantile(alg_pd$PD_COUNT_NEXT,.995, na.rm=T),alg_pd$PD_COUNT_NEXT,quantile(alg_pd$PD_COUNT_NEXT,.995, na.rm=T))
	#max(alg_pd$PD_COUNT_NEXT.capped ,na.rm=T) # Capped at 26 (21) PDs
	
	alg_pd$PAT_ENRL_COUNT.capped=ifelse(alg_pd$PAT_ENRL_COUNT<=quantile(alg_pd$PAT_ENRL_COUNT,.99, na.rm=T),alg_pd$PAT_ENRL_COUNT,quantile(alg_pd$PAT_ENRL_COUNT,.99, na.rm=T))
	#max(alg_pd$PAT_ENRL_COUNT.capped,na.rm=T) # 13; Capped at 12 (11) patients 

	alg_pd$PERIOD_LENGTH.CAPPED=ifelse(alg_pd$PERIOD_LENGTH<=quantile(alg_pd$PERIOD_LENGTH,.99,na.rm=T),alg_pd$PERIOD_LENGTH,quantile(alg_pd$PERIOD_LENGTH,.99,na.rm=T))
	#max(alg_pd$PERIOD_LENGTH.CAPPED, na.rm=T) # 1051 #812.96 (405)

#################### UPDATED REGRESSION MODEL POST DATA AGGREGATOR ######################## 

### Re-order the PD algorithm data by site and monitoring window start
alg_pd=alg_pd[order(alg_pd$HM_SITE_ID, alg_pd$PERIOD_START),]
#dim(alg_pd) #72,706s

alg_pd$MV.NUMBER=unlist(tapply(alg_pd$HM_SITE_ID, alg_pd$HM_SITE_ID, function(x){length(x):1}))

### Updated inclusion criteria for the PD module: ### 

number_before=dim(alg_pd)
logInfo("The number of sites retained BEFORE applying additional inclusion criteria due to Monitoring Visit data missingness", number_before)

num.per.use=4  # Maximum number of most recent monitoring windows to be used when fitting the model
per.length.max=365 # Maximum allowed length of monitoring window in days (based on the longest monitoring window in PAREXEL and ICON planned schedules)

pd.data.use=alg_pd[alg_pd$MV.NUMBER<=num.per.use    & alg_pd$PERIOD_LENGTH<=per.length.max & 
				alg_pd$PAT_COUNT_SCALE.capped>0, ]
number_after=dim(pd.data.use) # 14,687

logInfo("The number of sites retained AFTER applying additional inclusion criteria due to Monitoring Visit data missingness", number_after)

#max(pd.data.use$MV.NUMBER) #4
#max(pd.data.use$PERIOD_LENGTH) #365

### TRANSFORM VARIABLES BEFORE PD MODELS ARE FITTED #### 
cap.TIME_SINCE_FSFV=3*365 #Cap the variable at 3 years
pd.data.use$TIME_SINCE_FSFV.Capped=ifelse(pd.data.use$TIME_SINCE_FSFV>cap.TIME_SINCE_FSFV,cap.TIME_SINCE_FSFV,pd.data.use$TIME_SINCE_FSFV)

### Re-define COUNRY variable so that countries with fewer than 40 sites are grouped into "OTHER" bucket
### after the new inclusion/exclusion criteria are implemented

country.cap=40
temp=unique(pd.data.use[,c("HM_STUDY_ID","HM_SITE_ID","COUNTRY")])
sitespercountry <- table(temp$COUNTRY)
good.countries <- names(sitespercountry[sitespercountry>=country.cap])
pd.data.use$COUNTRY.FINAL <- as.factor(ifelse(pd.data.use$COUNTRY%in%good.countries,as.character(pd.data.use$COUNTRY),"OTHER"))
### During iterative development, BELGIUM had a significant and extreme negative coefficient for patient counts which is unusual
### Hence, sites in BELGIUM have been grouped into OTHER category
pd.data.use$COUNTRY.FINAL <- as.factor(ifelse(pd.data.use$COUNTRY.FINAL!="BELGIUM",as.character(pd.data.use$COUNTRY.FINAL),"OTHER"))

#temp=unique(pd.data.use[,c("HM_STUDY_ID","HM_SITE_ID","COUNTRY.FINAL")])
#min(table(temp$COUNTRY.FINAL)) # Minimum value should be equal to or greater than country.cap

### Re-Define STUDY variable so that studies with fewer than 10 sites are grouped into FEW OBS bucket

study.cap=10
temp=unique(pd.data.use[,c("HM_STUDY_ID","HM_SITE_ID")])
sitesperstudy <- table(temp$HM_STUDY_ID)
good.studies.trunc <- names(sitesperstudy [sitesperstudy >=study.cap])
pd.data.use$STUDY.FINAL <- as.factor(ifelse(pd.data.use$STUDY%in%good.studies.trunc ,as.character(pd.data.use$STUDY),"FEW OBS"))

#min(table(pd.data.use$STUDY.FINAL)) # Minimum value should be equal to or greater than study.cap

### Relationship Plots: Not Needed to be run in live environment; might be useful for PFE statistician to review  
#
#plot(jitter(pd.data.use$PERIOD_LENGTH), jitter(pd.data.use$PD_COUNT_NEXT.capped), pch=".", ylim=c(0,10))
#points(smooth.spline(pd.data.use$PERIOD_LENGTH, pd.data.use$PD_COUNT_NEXT.capped, cv=T), type="l", lwd=2, col="Red")

### NOTE: We CANNOT use Period_SINCE_FSFV anymore - as we cannot measure it accurately due mising MVI 
### Instead Time Since FSFV in Days is used

#plot(jitter(log(pd.data.use$TIME_SINCE_FSFV.Capped+1)), jitter(pd.data.use$PD_COUNT_NEXT.capped), pch=".", ylim=c(0,4))
#points(smooth.spline(log(pd.data.use$TIME_SINCE_FSFV.Capped+1), pd.data.use$PD_COUNT_NEXT.capped, spar=1), type="l", lwd=2, col="Orange")
# Inflection point is at about x=5, where x = log(pd.data.use$TIME_SINCE_FSFV.Capped+1)

### PAT_COUNT_SCALE.capped

#plot(jitter(pd.data.use$PAT_COUNT_SCALE.capped), jitter(pd.data.use$PD_COUNT_NEXT.capped), pch=".", ylim=c(0,6))
#points(smooth.spline(pd.data.use$PAT_COUNT_SCALE.capped, pd.data.use$PD_COUNT_NEXT.capped, spar=1.5), type="l", lwd=2, col="Orange")

#plot(jitter(log(pd.data.use$PAT_COUNT_SCALE.capped+1)), jitter(pd.data.use$PD_COUNT_NEXT.capped), pch=".", ylim=c(0,6))
#points(smooth.spline(log(pd.data.use$PAT_COUNT_SCALE.capped+1), pd.data.use$PD_COUNT_NEXT.capped, cv=T), type="l", lwd=2, col="Black")

### Relationship Plots between PAT_COUNT_SCALE.capped and PD_COUNT_NEXT.capped by cuntry 

#plot(jitter(log(pd.data.use$PAT_COUNT_SCALE.capped+1)), jitter(pd.data.use$PD_COUNT_NEXT.capped), pch=".", ylim=c(0,6))
#points(smooth.spline(log(pd.data.use$PAT_COUNT_SCALE.capped+1), pd.data.use$PD_COUNT_NEXT.capped, cv=T), type="l", lwd=2, col="Black")
#top.8.countries=names(sort(-table(pd.data.use$COUNTRY.FINAL)))[1:8]
#cols=rainbow(length(top.8.countries))
#col.i=1
#for (i in top.8.countries)
#{
#use.temp=which(pd.data.use$COUNTRY.FINAL==as.character(i))
#points(smooth.spline(log(pd.data.use$PAT_COUNT_SCALE.capped[use.temp]+1), pd.data.use$PD_COUNT_NEXT.capped[use.temp], spar=1.25),
#	 type="l", lwd=2, col=cols[col.i], lty=2)
#col.i=col.i+1
#}
#
#legend(0,6,legend=c(top.8.countries), col=cols, lty=2)


### ENROLLED PATIENT COUNT (Capped)

#pd.data.use$PAT_ENRL_COUNT.Capped =ifelse(pd.data.use$PAT_ENRL_COUNT>quantile(pd.data.use$PAT_ENRL_COUNT,.99),
#				quantile(pd.data.use$PAT_ENRL_COUNT,.99), pd.data.use$PAT_ENRL_COUNT)
#table(pd.data.use$PAT_ENRL_COUNT.Capped)

#plot(jitter(pd.data.use$PAT_ENRL_COUNT.Capped ), jitter(pd.data.use$PD_COUNT_NEXT), pch=".", ylim=c(0,6))
#points(smooth.spline(pd.data.use$PAT_ENRL_COUNT.Capped, pd.data.use$PD_COUNT_NEXT.capped, cv=T, tol=.1), type="l", lwd=2, col="Red")
#points(smooth.spline(pd.data.use$PERIOD_LENGTH, pd.data.use$PD_COUNT_NEXT.capped, spar=.9), type="l", lwd=2, col="Orange")

#### Ratio of Enrolled to Total Patients

#plot(jitter(pd.data.use$PAT_ENRL_COUNT/pd.data.use$PAT_COUNT), jitter(pd.data.use$PD_COUNT_NEXT), pch=".", ylim=c(0,6))
#points(smooth.spline(pd.data.use$PAT_ENRL_COUNT/pd.data.use$PAT_COUNT, pd.data.use$PD_COUNT_NEXT.capped, cv=T, tol=.1), type="l", lwd=2, col="Red")

############ MODEL FOR PREDICTING PDs IN A MONITORING WINDOW (Reflects new Inclusion Criteria as of May 27, 2014) ############### 

logInfo("Fitting the regression model to predict the number of PDs in a monitoring window based on a number of site and study characteristics")
	row.names(pd.data.use)=1:nrow(pd.data.use)
	fit.lm3 <- lm(PD_COUNT_NEXT.capped ~ as.factor(STUDY.FINAL)+COUNTRY.FINAL+ COUNTRY.FINAL:log(PAT_COUNT_SCALE.capped+1)+
			log(TIME_SINCE_FSFV.Capped+1)+I(as.numeric(log(TIME_SINCE_FSFV.Capped+1)-5>0)*(log(TIME_SINCE_FSFV.Capped+1)-5))+
			log(TIME_SINCE_FSFV.Capped+1)*log(PERIOD_LENGTH+1),
			data=pd.data.use, weights=sqrt(pd.data.use$PAT_COUNT_SCALE.capped))
	
	# summary(fit.lm3) # <- Summarizes the fitted model 

	r.sq.lm3=summary(fit.lm3)$r.sq
	logInfo("Unadjusted R-Squared from the PD Regression Model", r.sq.lm3)
	logInfo("The unadjusted R-Squared printed out above should be in the 10-20% range")

	# Predicted PD Values
	#pd.data.use$fit_pd <- ifelse(predict(fit.lm3,pd.data.use)<0,0,predict(fit.lm3,pd.data.use))
	#summary(pd.data.use$fit_pd)

	# Difference between actual and predicted PD values = PD Delta
	#pd.data.use$fit_pd_resid = pd.data.use$PD_COUNT_NEXT - pd.data.use$fit_pd
	
	# PD Delta percentiles 
	#pd.data.use$fit_pd_resid_percentile <- rank(pd.data.use$fit_pd_resid, na.last="keep")/sum(!is.na(pd.data.use$fit_pd_resid))
	
	#summary(pd.data.use$fit_pd_resid)
	#summary(pd.data.use$fit_pd_resid_percentile)

########### APPLICATION OF FITTED MODEL COEFFICIENTS TO VISUALIZED STUDIES AND CALCULATION OF PERCENTILES ####### 

# Subset to only "ongoing" studies for visualization purposes

	# Create List of Studies with at least one ongoing site with at least one enrolled patient
	# Currently this is set up to visualize all monitoring windows, not just the four most recent ones 

	alg_pd_ongoing=alg_pd[alg_pd$PERIOD_LENGTH<=per.length.max & alg_pd$PAT_COUNT_SCALE.capped>0, ]
	studies_for_viz <- V_W_PD_IN_CLINICAL_STUDY[which(V_W_PD_IN_CLINICAL_STUDY$YN_VISUALIZE %in% c("Y")),]
	alg_pd_ongoing <- alg_pd_ongoing[which(alg_pd_ongoing$HM_STUDY_ID %in% studies_for_viz$HM_STUDY_ID),]
	alg_pd_ongoing <- alg_pd_ongoing[which(	as.Date(alg_pd_ongoing$PERIOD_END) <=Sys.Date() & alg_pd_ongoing$PAT_COUNT>0),]

	# Ensure that the factor levels for the expanded data set match the factor values used in the model

	alg_pd_ongoing$STUDY.FINAL=as.factor(ifelse(alg_pd_ongoing$STUDY%in%unique(pd.data.use$STUDY.FINAL),
					as.character(alg_pd_ongoing$STUDY), "FEW OBS"))
	alg_pd_ongoing$COUNTRY.FINAL=as.factor(ifelse(alg_pd_ongoing$COUNTRY%in%unique(pd.data.use$COUNTRY.FINAL),
					as.character(alg_pd_ongoing$COUNTRY), "OTHER"))
	alg_pd_ongoing$TIME_SINCE_FSFV.Capped=ifelse(alg_pd_ongoing$TIME_SINCE_FSFV>cap.TIME_SINCE_FSFV,cap.TIME_SINCE_FSFV,
					alg_pd_ongoing$TIME_SINCE_FSFV)

	# Apply the fitted PD model to the ongoing data 

	alg_pd_ongoing$fit_pd <- ifelse(predict(fit.lm3,alg_pd_ongoing)<0,0,predict(fit.lm3,alg_pd_ongoing))
	alg_pd_ongoing$fit_pd_resid = alg_pd_ongoing$PD_COUNT_NEXT - alg_pd_ongoing$fit_pd
	alg_pd_ongoing$fit_pd_resid_percentile <- rank(alg_pd_ongoing$fit_pd_resid, na.last="keep")/sum(!is.na(alg_pd_ongoing$fit_pd_resid))
	#summary(alg_pd_ongoing$fit_pd_resid_percentile)
	
	# Add the PK column for RODBC/sqlSave function
	alg_pd_ongoing$HM_WRK_PD_OUT_HIST_ID <- NA

	# Adjust and Rename Variables for Output to the Data Mart 
	PD_OUT_HIST <- alg_pd_ongoing[,c("HM_WRK_PD_OUT_HIST_ID","HM_STUDY_ID","HM_SITE_ID","PERIOD_START","PERIOD_END","PAT_COUNT", 
	"PAT_COUNT_SCALE","PERIOD_LENGTH", "PD_COUNT_NEXT","fit_pd","fit_pd_resid_percentile")]
	
	names(PD_OUT_HIST) <- c("HM_WRK_PD_OUT_HIST_ID","HM_STUDY_ID","HM_SITE_ID","PERIOD_START","PERIOD_END","PATIENT_COUNT",
	"PATIENT_COUNT_SCALE","PERIOD_LENGTH","PD_COUNT_ACUAL","PD_COUNT_EXPECTED","PD_PERCENTILE")

	# Insert into WRK_PD_OUT_HIST using RODBCDataInsert function
	source("/app/r/engine/RODBCDataInsert.R")
	
	logInfo("Saving PD Model results to WRK_PD_OUT_HIST...")	
	insertPDOutHist(PD_OUT_HIST)
	# write.csv(file="WRK_PD_OUT_HIST.csv", x=PD_OUT_HIST)
	logInfo("Done saving PD Model results to WRK_PD_OUT_HIST...")
	
	# dim(PD_OUT_HIST) #13,660 - much smaller than before
	# write.csv(PD_OUT_HIST,file=paste(lib.outmodel,"PD_OUT_HIST.csv",sep=""))
 
	##### CALCULATE LAGGED RESIDUALS

	#Function to get Lagged values (of varying number of periods) by HM_CLINICAL_STUDY_SITE
	lag_function <- function(x,lagperiod,data.used){
		temp <- c(rep(NA,lagperiod),x[1:(length(x)-lagperiod)])
		temp[data.used$HM_SITE_ID != c(rep(NA,lagperiod),
				data.used$HM_SITE_ID[1:(length(x)-lagperiod)])] <- NA
		temp
	}

	alg_pd_ongoing <- alg_pd_ongoing[order(alg_pd_ongoing$HM_SITE_ID,alg_pd_ongoing$PERIOD_START),]
	alg_pd_ongoing $PERIOD_START_lag1 <- as.Date(lag_function(alg_pd_ongoing $PERIOD_START,1,alg_pd_ongoing), origin="1970-01-01")
	alg_pd_ongoing $PERIOD_START_lag2 <- as.Date(lag_function(alg_pd_ongoing $PERIOD_START,2,alg_pd_ongoing), origin="1970-01-01")
	alg_pd_ongoing $PERIOD_START_lag3 <- as.Date(lag_function(alg_pd_ongoing $PERIOD_START,3,alg_pd_ongoing), origin="1970-01-01")

	alg_pd_ongoing$PERIOD_END_lag1 <- as.Date(lag_function(alg_pd_ongoing$PERIOD_END,1,alg_pd_ongoing), origin="1970-01-01")
	alg_pd_ongoing$PERIOD_END_lag2 <- as.Date(lag_function(alg_pd_ongoing$PERIOD_END,2,alg_pd_ongoing), origin="1970-01-01")
	alg_pd_ongoing$PERIOD_END_lag3 <- as.Date(lag_function(alg_pd_ongoing$PERIOD_END,3,alg_pd_ongoing), origin="1970-01-01")

	alg_pd_ongoing$fit_pd_lag1 <- lag_function(alg_pd_ongoing$fit_pd,1,alg_pd_ongoing)
	alg_pd_ongoing$fit_pd_lag2 <- lag_function(alg_pd_ongoing$fit_pd,2,alg_pd_ongoing)
	alg_pd_ongoing$fit_pd_lag3 <- lag_function(alg_pd_ongoing$fit_pd,3,alg_pd_ongoing)

	alg_pd_ongoing$fit_pd_resid_lag1 <- lag_function(alg_pd_ongoing$fit_pd_resid,1,alg_pd_ongoing)
	alg_pd_ongoing$fit_pd_resid_lag2 <- lag_function(alg_pd_ongoing$fit_pd_resid,2,alg_pd_ongoing)
	alg_pd_ongoing$fit_pd_resid_lag3 <- lag_function(alg_pd_ongoing$fit_pd_resid,3,alg_pd_ongoing)

	alg_pd_ongoing$PD_COUNT_NEXT_lag1 <- lag_function(alg_pd_ongoing$PD_COUNT_NEXT,1,alg_pd_ongoing)
	alg_pd_ongoing$PD_COUNT_NEXT_lag2 <- lag_function(alg_pd_ongoing$PD_COUNT_NEXT,2,alg_pd_ongoing)
	alg_pd_ongoing$PD_COUNT_NEXT_lag3 <- lag_function(alg_pd_ongoing$PD_COUNT_NEXT,3,alg_pd_ongoing)

	alg_pd_ongoing$fit_pd_resid_percentile_lag1 <- lag_function(alg_pd_ongoing$fit_pd_resid_percentile,1,alg_pd_ongoing)
	alg_pd_ongoing$fit_pd_resid_percentile_lag2 <- lag_function(alg_pd_ongoing$fit_pd_resid_percentile,2,alg_pd_ongoing)
	alg_pd_ongoing$fit_pd_resid_percentile_lag3 <- lag_function(alg_pd_ongoing$fit_pd_resid_percentile,3,alg_pd_ongoing)

	
	# Grab the most recent row (and accompanying residuals from previous 3 periods)
	last_index <- tapply(alg_pd_ongoing$PERIOD_SINCE_FSFV,alg_pd_ongoing$HM_SITE_ID,max)
	alg_pd_ongoing <- merge(alg_pd_ongoing,last_index,by.x="HM_SITE_ID",by.y=0,all.x=T)
	
	alg_pd_ongoing_last <- alg_pd_ongoing[which(alg_pd_ongoing$PERIOD_SINCE_FSFV==alg_pd_ongoing$y),]

	dim(alg_pd_ongoing_last) # 1,820 sites (compared to 7,573 (2,761) sites before) 

	# Save for SH Scoring module
	save(alg_pd_ongoing_last, file="PD_Model.Rdata", ascii=FALSE)

	PD_OUT <- merge(alg_pd_ongoing_last, V_W_PD_IN_CLINICAL_STUDY[,c("HM_STUDY_ID","PFIZER_PROTOCOL_ID")], by="HM_STUDY_ID",all.x=T)
		
	# Add the PK column for RODBC/sqlSave function
	PD_OUT$HM_WRK_PD_OUT_ID <- NA

	# Adjust and Rename Variables for Output to the Data Mart 
	PD_OUT <- PD_OUT[,c("HM_WRK_PD_OUT_ID", "HM_SITE_ID", "HM_STUDY_ID","PFIZER_PROTOCOL_ID", "PERIOD_START", "PERIOD_END","PAT_COUNT",
	"PAT_COUNT_SCALE", "PERIOD_LENGTH", "PD_COUNT_NEXT", "PD_COUNT_NEXT_lag1", "PD_COUNT_NEXT_lag2", "PD_COUNT_NEXT_lag3",
	"fit_pd", "fit_pd_lag1","fit_pd_lag2","fit_pd_lag3","fit_pd_resid", "fit_pd_resid_percentile")]

	names(PD_OUT) <- c("HM_WRK_PD_OUT_ID", "HM_SITE_ID", "HM_STUDY_ID", "PFIZER_PROTOCOL_ID","PERIOD_START_CURRENT","PERIOD_END_CURRENT","PATIENT_COUNT",
	"PATIENT_COUNT_SCALE","CURRENT_PERIOD_LENGTH","PD_COUNT_ACTUAL_CURRENT","PD_COUNT_ACTUAL_T1","PD_COUNT_ACTUAL_T2","PD_COUNT_ACTUAL_T3",
	"PD_COUNT_EXPECTED_CURRENT", "PD_COUNT_EXPECTED_T1", "PD_COUNT_EXPECTED_T2","PD_COUNT_EXPECTED_T3","DELTA_CURRENT","PD_PERCENTILE_CURRENT")

	# Insert into WRK_PD_OUT using RODBCDataInsert function
	logInfo("Saving PD Model results to WRK_PD_OUT...")	
 	insertPDOut(PD_OUT)
	# write.csv(file="WRK_PD_OUT.csv", x=PD_OUT)
	logInfo("Completed saving PD Model results to WRK_PD_OUT...")
	logInfo("<DONE> - Exiting PD module...")

### END OF APPLICATION OF MODEL COEFFICIENTS TO ONGOING STUDIES ### 
