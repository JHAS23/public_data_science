# --------------
# Title: utilities_input.R
# --------------
# Author: Kevin Coltin (kcoltin@deloitte.com)
# Date: Nov 16 2016
# --------------
# Description: Contains functions for loading raw data into R
# --------------
# Author:
# Date:
# Modification:
# --------------


# Loads input data necessary to run the modules. Data is loaded either from
# the Oracle database or from CSV files, depending on whether the user requested
# the "CSV" option.
load_input_data <- function() {
  Out <- list() # List of data frames - this will be the output of the function

  Out$Sites <- load_site_data()
  Out$Studies <- load_study_data()
  Out$Subjects <- load_subject_data()
  Out$Patient.visits <- load_patient_visit_data()
  Out$Staff <- load_staff_data()
  Out$AEs <- load_AE_data()
  Out$SAEs <- load_SAE_data()

  if (RUN.PD.MODULE) { # PD data is not used by any other modules
    Out$PDs <- load_PD_data()
    Out$PD.monitoring <- load_PD_monitoring_data()
  }

  Out[c("Oversight.reports", "Issues")] <- load_issue_data()

  return(Out)
}


# Load data on study sites
load_site_data <- function() {
  VIEWNAME <- "V_W_RT_IN_CLINICAL_STUDY_SITE"
  if (CSV.INPUT) {
    Sites <- read_raw_data_from_csv(VIEWNAME)
  }
  else {
    Sites <- read_db_table(VIEWNAME)
  }
  Sites <- Sites[!is.na(Sites$YN_EXCLUDED) & Sites$YN_EXCLUDED == "N",]
  cat("Loaded", nrow(Sites), "rows from", VIEWNAME, "\n", file=log_con)

  # Some dates in SITE_FSFV_DATE_DERIVED are unrealistically early - replace
  # these with the plain SITE_FSFV_DATE field
  ix <- !is.na(Sites$SITE_FSFV_DATE_DERIVED) &
          Sites$SITE_FSFV_DATE_DERIVED <= as.Date("2000-01-01")
  Sites[ix,"SITE_FSFV_DATE_DERIVED"] <- Sites[ix,"SITE_FSFV_DATE"]

  #write.table(Sites,file="/app/r/engine/Data/Database_data/V_W_RT_IN_CLINICAL_STUDY_SITE",sep='\t',quote=F,row.names=F);
  return(Sites)
}


# Load data on studies
load_study_data <- function() {
  VIEWNAME <- "V_W_RT_IN_CLINICAL_STUDY"
  if (CSV.INPUT) {
    Studies <- read_raw_data_from_csv(VIEWNAME)
  }
  else {
    Studies <- read_db_table(VIEWNAME)
  }
  Studies <- Studies[!is.na(Studies$YN_EXCLUDED) & Studies$YN_EXCLUDED == "N",]
  cat("Loaded", nrow(Studies), "rows from", VIEWNAME, "\n", file=log_con)

  # Filter out studies with phase "N/A"
  ix.drop <- which(Studies$DEVELOPMENT_PHASE == "N/A (NOT APPLICABLE)")
  if (length(ix.drop) > 0) {
    Studies <- Studies[-ix.drop,]
    cat("Dropping", length(ix.drop), "studies because their development",
        "phase is 'N/A (NOT APPLICABLE)'.\n", file=log_con)
  }
  # Check for new values found for study phases
  new.values <- setdiff(Studies$DEVELOPMENT_PHASE, DEVELOPMENT.PHASES)
  if (length(new.values) > 0) {
    cat("WARNING: New values found in DEVELOPMENT_PHASE. The new values are:",
        paste(new.values, collapse=", "), "\n", file=log_con)
  }
  
  #write.table(Studies,file="/app/r/engine/Data/Database_data/V_W_RT_IN_CLINICAL_STUDY",sep='\t',quote=F,row.names=F);
##################################################################33
########################### New Change ###################################
################ NO NON INTERVENTIONAL Studies
#####################################################################
  Studies=Studies[! Studies$STUDY_TYPE %in% "NON INTERVENTIONAL",];


  #write.table(Studies,file="/app/r/engine/Data/Database_data/V_W_RT_IN_CLINICAL_STUDY_filtered",sep='\t',quote=F,row.names=F);
  return(Studies)
}

# Load data on subjects
load_subject_data <- function() {
  VIEWNAME <- "V_W_RT_IN_SUBJECT"
  if (CSV.INPUT) {
    Subjects <- read_raw_data_from_csv(VIEWNAME)
  }
  else {
    Subjects <- read_db_table(VIEWNAME)
  }
  cat("Loaded", nrow(Subjects), "rows from", VIEWNAME, "\n", file=log_con)
  return(Subjects)
}


# Load data on patient visits
load_patient_visit_data <- function() {
  VIEWNAME <- "V_W_TL_IN_CRF_DATA_ENTRY_COMPL"
  if (CSV.INPUT) {
    Patient.visits <- read_raw_data_from_csv(VIEWNAME)
    # Perform some data processing steps - these are already applied to the
    # views in Unix, so they only need to be done when using CSV input.
    Patient.visits[is.na(Patient.visits$VISIT_COUNT),"VISIT_COUNT"] <- 0
    Patient.visits[is.na(Patient.visits$COMPLIANT_COUNT),"COMPLIANT_COUNT"] <- 0
    Patient.visits$VISIT_COUNT <- pmax(Patient.visits$VISIT_COUNT,
                                       Patient.visits$COMPLIANT_COUNT,
                                       na.rm=TRUE)
  }
  else {
    Patient.visits <- read_db_table(VIEWNAME)
  }
  cat("Loaded", nrow(Patient.visits), "rows from", VIEWNAME, "\n",
      file=log_con)

 #write.table(Patient.visits,file="/app/r/engine/Data/Database_data/V_W_RT_IN_SUBJECT",sep='\t',quote=F,row.names=F); 
 return(Patient.visits)
}

##################################################################33
########################### New Change ###################################
########### Remove all instances of a HM_SITE_ID,HM_PERSON_ID when there is a status change on the same day. If the status does not change then only include 1 row.
cleanupstaff =function(Staff) {
########### Remove all instances of a HM_SITE_ID,HM_PERSON_ID when there is a status change on the same day. If the status does not change then only include 1 row.
#Keeping track of rownames
 Staff$rid=rownames(Staff);
 x=strsplit(as.vector(as.character(Staff$STATUS_DATE))," "); Staff$STATUS_DATE=sapply(x,"[",1);
 Staff=Staff[order(Staff$HM_SITE_ID,Staff$HM_PERSON_ID,Staff$STATUS_DATE),];
#Keeping only one entry if a person has the same status on the same day mulktiple number of times
 t=Staff[,c("HM_SITE_ID","HM_PERSON_ID","STATUS_DATE","CONTACT_STATUS")];
 p=unique(t);
 Staff=Staff[Staff$rid %in% rownames(p),];
#Converting the string to Date
 Staff$x=as.Date(Staff$STATUS_DATE);
 Staff.next <- Staff[2:nrow(Staff),];
 Staff.prev <- Staff[1:(nrow(Staff)-1),];
 x1=ifelse(Staff.next$HM_PERSON_ID == Staff.prev$HM_PERSON_ID & Staff.next$HM_SITE_ID == Staff.prev$HM_SITE_ID,Staff.next$x - Staff.prev$x,99);
 x1[length(x1)+1]=99;
 Staff$x1=x1;
 r=Staff[Staff$x1 ==0,c("HM_SITE_ID","HM_PERSON_ID","STATUS_DATE")];
 p1=paste(as.vector(Staff$HM_SITE_ID),as.vector(Staff$HM_PERSON_ID),as.character(Staff$STATUS_DATE));
 Staff$p1=p1;
 p2=paste(as.vector(r$HM_SITE_ID),as.vector(r$HM_PERSON_ID),as.character(r$STATUS_DATE));
 Staff=Staff[! Staff$p1 %in% p2,];
 Staff=Staff[,! names(Staff) %in% c("rid","x","x1","p1")];
 Staff$STATUS_DATE=as.Date(Staff$STATUS_DATE);

 return(Staff);
}


# Load data on staff
load_staff_data <- function() {
#  print("Function - load_staff_data");
  VIEWNAME <- "V_W_RT_IN_SITE_PERS_TURNOVER"
  if (CSV.INPUT) {
    Staff <- read_raw_data_from_csv(VIEWNAME)
  }
  else {
    Staff <- read_db_table(VIEWNAME)
  }
  Staff <- Staff[!is.na(Staff$YN_EXCLUDED) & Staff$YN_EXCLUDED == "N",]
#  print(Staff[1,]);
##################################################################33
########################### New Change ###################################
########### Remove instances where status change happen in the same day

  #write.table(Staff,file="/app/r/engine/Data/Database_data/V_W_RT_IN_SITE_PERS_TURNOVER",sep='\t',quote=F,row.names=F); 
  Staff=cleanupstaff(Staff);
  #write.table(Staff,file="/app/r/engine/Data/Database_data/V_W_RT_IN_SITE_PERS_TURNOVER_revised",sep='\t',quote=F,row.names=F);
  cat("Loaded", nrow(Staff), "rows from", VIEWNAME, "\n", file=log_con)
  return(Staff)
}

# Load data on adverse events
load_AE_data <- function() {
  VIEWNAME <- "V_W_AE_IN_ADVERSE_EVENT"
  if (CSV.INPUT) {
    AEs <- read_raw_data_from_csv(VIEWNAME)
  }
  else {
    AEs <- read_db_table(VIEWNAME)
  }
  AEs <- AEs[!is.na(AEs$YN_EXCLUDED) & AEs$YN_EXCLUDED == "N",]
  cat("Loaded", nrow(AEs), "rows from", VIEWNAME, "\n", file=log_con)
  return(AEs)
}

# Load data on severe adverse events
load_SAE_data <- function() {
  VIEWNAME <- "V_W_SAE_IN_SAE_CASE"
  if (CSV.INPUT) {
    SAEs <- read_raw_data_from_csv(VIEWNAME)
  }
  else {
    SAEs <- read_db_table(VIEWNAME)
  }
  cat("Loaded", nrow(SAEs), "rows from", VIEWNAME, "\n", file=log_con)
  return(SAEs)
}

# Load data on protocol deviations
load_PD_data <- function() {
  VIEWNAME <- "V_W_PD_IN_PROTOCOL_DEVIATION"
  if (CSV.INPUT) {
    PDs <- read_raw_data_from_csv(VIEWNAME)
  }
  else {
    PDs <- read_db_table(VIEWNAME)
  }
  PDs <- PDs[!is.na(PDs$YN_INCONSISTENT_PD) & PDs$YN_INCONSISTENT_PD == "N",]
  cat("Loaded", nrow(PDs), "rows from", VIEWNAME, "\n", file=log_con)
  return(PDs)
}

# Load data on protocol deviation monitoring visits
load_PD_monitoring_data <- function() {
  VIEWNAME <- "V_W_PD_IN_SITE_VISIT"
  if (CSV.INPUT) {
    PD.monitoring <- read_raw_data_from_csv(VIEWNAME)
  } else {
    PD.monitoring <- read_db_table(VIEWNAME)
  }
  cat("Loaded", nrow(PD.monitoring), "rows from", VIEWNAME, "\n",
      file=log_con)

  # Filter out visit types other than PD visits
  PD.monitoring <- PD.monitoring[PD.monitoring$VISIT_REPORT_TYPE
                                 == "MONITORING VISIT REPORT",]

  cat(paste0(nrow(PD.monitoring), " rows remain from ", VIEWNAME,
             ", after dropping rows that are not PD Monitoring Visits\n"),
      file=log_con)
  return(PD.monitoring)
}

# Load data on oversight reports and issues found at sites
load_issue_data <- function() {
  # Load raw issues
  VIEWNAME <- "V_W_RT_IN_OR_RISK_CAT_COUNTS"
  if (CSV.INPUT) {
    Issues <- read_raw_data_from_csv(VIEWNAME)
  }
  else {
    Issues <- read_db_table(VIEWNAME)
  }
  cat("Loaded", nrow(Issues), "rows from", VIEWNAME, "\n", file=log_con)

  # Load oversight reports
  VIEWNAME <- "V_W_RT_IN_OVERSIGHT_REPORTS"
  if (CSV.INPUT) {
    Oversight.reports <- read_raw_data_from_csv(VIEWNAME)
  }
  else {
    Oversight.reports <- read_db_table(VIEWNAME)
  }
  cat("Loaded", nrow(Oversight.reports), "rows from", VIEWNAME, "\n",
      file=log_con)


  # Remove "Total issues", "Issues not raised", and "Subject visits review"
  # (The spelling of "SUBJECT VISITS REVIE" is correct, there's no W at the end)
  Issues <- Issues[!Issues$RISK_CATEGORY %in%
                  c("TOTAL ISSUES","ISSUES NOT RAISED","SUBJECT VISITS REVIE"),]
  # Cap issues at one per report for two categories in particular
  Issues$RISK_CATEGORY_COUNT.capped <- ifelse(Issues$RISK_CATEGORY
                                          %in% c("DATA", "ESSENTIAL_DOCUMENTS"),
                                            pmin(1, Issues$RISK_CATEGORY_COUNT),
                                            Issues$RISK_CATEGORY_COUNT)

  # In cases where two or more oversight reports were listed within a very short
  # timeframe, just drop all but one (they seem to be duplicates) and keep the
  # one with the greatest number of issues, using the higher ID number (which
  # was presumably submitted more recently) as a tiebreaker. This method isn't
  # perfect, but it's correct most of the time, and this problem is so rare that
  # it's not worth the complexity and additional bugs that could be introduced
  # by a different solution.
  Oversight.reports <- merge(Oversight.reports,
                             aggregate(Issues["RISK_CATEGORY_COUNT"],
                                     by=Issues["HM_GL_IN_OVERSIGHT_REPORTS_ID"],
                                       FUN=sum),
                             all.x=TRUE)
  Oversight.reports[is.na(Oversight.reports$RISK_CATEGORY_COUNT),
                    "RISK_CATEGORY_COUNT"] <- 0
  # What we're doing here is filtering out rows which have another report
  # occurring within the same 7 days - in that case, we are going to keep the
  # report which has more issues; in a tie, default to the newer one (higher ID)
  # Note: This works acceptably even in weird edge cases where there are
  # multiple reports within a time frame.
  f <- function(report.id, site.id, report.start.date, risk.cat.count) {
    return(any(site.id == Oversight.reports$HM_SITE_ID
              & abs(report.start.date - Oversight.reports$REPORT_START_DATE) < 7
              & (risk.cat.count < Oversight.reports$RISK_CATEGORY_COUNT
                 | (risk.cat.count == Oversight.reports$RISK_CATEGORY_COUNT
                   & report.id < Oversight.reports$HM_GL_IN_OVERSIGHT_REPORTS_ID
           ))))
  }
  duplicates <- mapply(f, Oversight.reports$HM_GL_IN_OVERSIGHT_REPORTS_ID,
                          Oversight.reports$HM_SITE_ID,
                          Oversight.reports$REPORT_START_DATE,
                          Oversight.reports$RISK_CATEGORY_COUNT)
  Oversight.reports <- Oversight.reports[!duplicates,]
  Oversight.reports$RISK_CATEGORY_COUNT <- NULL

  # Filter out issues related to invalid/duplicate reports
  Issues <- Issues[Issues$HM_GL_IN_OVERSIGHT_REPORTS_ID
                   %in% Oversight.reports$HM_GL_IN_OVERSIGHT_REPORTS_ID,]
  # Add REPORT_START_DATE and HM_SITE_ID to Issues dataset
  Issues <- merge(Issues,
                  Oversight.reports[c("HM_GL_IN_OVERSIGHT_REPORTS_ID",
                                      "HM_SITE_ID", "REPORT_START_DATE")],
                  by="HM_GL_IN_OVERSIGHT_REPORTS_ID")

  cat(nrow(Oversight.reports), "oversight reports and", nrow(Issues),
      "oversight issues remain after applying various filtering rules\n",
      file=log_con)

  return(list(Oversight.reports, Issues))
}


# Removes leading and trailing whitespace from a string
trim <- function(s) {
  s <- sub("^ +", "", s) # remove leading spaces
  s <- sub(" +$", "", s) # remove trailing spaces
  return(s)
}


# Reads in a view from the Oracle database and applies certain data cleaning
# and formatting operations
#
# Args:
#   table.name: Name of the database table to read in. This should be the name
#     of the table only, for example V_W_MY_TABLE rather than
#     HM_DM_WRK_OWNER.V_W_MY_TABLE
#
# Returns: The complete contents of the table, as a data frame
read_db_table <- function(table.name) {
  # Read in the table/view from the Oracle database
  db.channel <- connect_to_database()
  table.name <- paste0(DATABASE.NAME, ".", table.name)
  Data <- try(sqlQuery(db.channel, paste("select * from", table.name)),
              silent=TRUE)
  if (inherits(Data, "try-error")) {
    try(close(db.channel), silent=TRUE)
    stop(paste("ERROR reading table", table.name, "from database"))
  }
  # Confirm that the correct number of rows were read in
  row.count <- as.integer(sqlQuery(db.channel,
                                   paste("select count(*) from", table.name)))
  if (row.count != nrow(Data)) {
    try(close(db.channel), silent=TRUE)
    stop(paste("ERROR reading table", table.name, "from database:", nrow(Data),
               "rows were read in, but the table contains", row.count, "rows"))
  }
  try(close(db.channel), silent=TRUE)

  # Trim whitespace and uppercase all character and factor values
  for (factor.var in names(Data)[sapply(Data, is.factor)]) {
    levels(Data[[factor.var]]) <- toupper(trim(levels(Data[[factor.var]])))
  }
  for (char.var in names(Data)[sapply(Data, is.character)]) {
    Data[char.var] <- toupper(trim(Data[[char.var]]))
  }

  # Convert POSIX datetime types to Dates. This makes it possible to
  # consistently compare dates, subtract dates to calculate differences in terms
  # of number of days, etc.
  for (dt.var in names(Data)[sapply(Data, function(v) inherits(v, "POSIXt"))]) {
    Data[dt.var] <- as.Date(Data[[dt.var]])
  }
  # Warn if any variables that appear to be dates are not stored as dates
  varnames <- names(Data)[(grepl("DATE", names(Data)) | grepl("DT",names(Data)))
                          & !sapply(Data, function(v) inherits(v, "Date"))]
  if (length(varnames) > 0) {
    cat("WARNING: The following variables appear to be dates, but were not",
        "read in as Date datatypes:", paste(varnames, collapse=", "), "\n",
        file=log_con)
  }

  return(Data)
}


# Reads in a CSV file and applies certain data cleaning and formatting
# operations
#
# Args:
#   table.name: Name of the database table corresponding to the CSV file to read
#     in. For example, if table name = "MY_TABLE", then the function will read
#     the file Data/Database_data/MY_TABLE.csv.
#     This should be the name of the table only, for example V_W_MY_TABLE
#     rather than HM_DM_WRK_OWNER.V_W_MY_TABLE
#
# Returns: The CSV file, as a data frame
read_raw_data_from_csv <- function(table.name) {
  full.filename <- file.path(DATABASE.DATA.DIR, paste0(table.name, ".csv"))
  Data <- try(read.csv(full.filename, na.strings=c("", "NA", "#N/A")), silent=TRUE)
  if (!is.data.frame(Data)) {
    stop(paste0("Unable to read CSV file ", full.filename, "; check that",
                "file exists and is in CSV format. ", as.character(Data)))
  }

  names(Data) <- toupper(trim(names(Data)))

  # Trim whitespace and uppercase all character and factor values
  for (factor.var in names(Data)[sapply(Data, is.factor)]) {
    levels(Data[[factor.var]]) <- toupper(trim(levels(Data[[factor.var]])))
  }
  for (char.var in names(Data)[sapply(Data, is.character)]) {
    Data[char.var] <- toupper(trim(Data[[char.var]]))
  }

  # Cycle over all character columns, and see if they can be converted to dates
  # (i.e. if all values are either N/A or are in a date format, like
  # '2016-11-21')
  for (col in names(Data)) {
    if (is.character(col) || is.factor(col)) {
      date.col <- try(as.Date(Data[[col]]), silent=TRUE)
      # If all non-N/A values could be converted into dates, then convert the
      # entire column into Date
      if (inherits(date.col, "Date")
          && all(is.na(date.col) == is.na(Data[[col]]))) {
        Data[col] <- date.col
      }
    }
  }

  # Warn if any variables that appear to be dates are not stored as dates
  varnames <- names(Data)[(grepl("DATE", names(Data)) | grepl("DT",names(Data)))
                          & !sapply(Data, function(v) inherits(v, "Date"))]
  if (length(varnames) > 0) {
    cat("WARNING: The following variables appear to be dates, but were not ",
        "read in as Date datatypes:", paste(varnames, collapse=", "), "\n",
        file=log_con)
  }

  return(Data)
}


